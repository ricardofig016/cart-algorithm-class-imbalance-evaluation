{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCART Implementation for Class Imbalance Study\\n\\nOriginal Reference Implementation:\\n- Adapted from zziz/cart (https://github.com/zziz/cart)\\n- Clean-room implementation without direct code copying\\n\\nKey Modifications from Reference:\\n1. Architecture Simplification:\\n   - Removed regression functionality to focus purely on classification\\n   - Unified tree structure with dedicated TreeNode class\\n   - Simplified API (removed pruning parameters, consolidated initialization)\\n\\n2. Project-Specific Optimizations:\\n   - Direct compatibility with preprocessed numpy arrays (from data/processed/)\\n   - Binary classification focus with class label tracking\\n   - Early stopping criteria aligned with imbalance analysis needs\\n   - Memory-efficient node structure for large datasets\\n\\n3. Phase 2 Readiness:\\n   - Modular impurity calculations for weighted Gini modification\\n   - Class label preservation for imbalance weighting\\n   - Predict method optimized for probability-based metrics (ROC-AUC)\\n\\nImplementation Differences from Reference:\\n- No sklearn dependencies\\n- Removed print_tree visualization methods\\n- Simplified split criteria to essential parameters\\n- Vectorized impurity calculations for performance\\n- Added sample counting for imbalance analysis\\n\\nImportant Notes:\\n- Designed for binary classification (handles multi-class through majority voting)\\n- Requires preprocessed numerical features (compatible with utils/preprocess.py)\\n- Class labels stored in self.classes for Phase 2 modifications\\n\\nMaintains Core CART Functionality:\\n- Gini/Entropy split criteria\\n- Depth-based stopping\\n- Recursive tree construction\\n- Majority class prediction\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "CART Implementation for Class Imbalance Study\n",
    "\n",
    "Original Reference Implementation:\n",
    "- Adapted from zziz/cart (https://github.com/zziz/cart)\n",
    "- Clean-room implementation without direct code copying\n",
    "\n",
    "Key Modifications from Reference:\n",
    "1. Architecture Simplification:\n",
    "   - Removed regression functionality to focus purely on classification\n",
    "   - Unified tree structure with dedicated TreeNode class\n",
    "   - Simplified API (removed pruning parameters, consolidated initialization)\n",
    "\n",
    "2. Project-Specific Optimizations:\n",
    "   - Direct compatibility with preprocessed numpy arrays (from data/processed/)\n",
    "   - Binary classification focus with class label tracking\n",
    "   - Early stopping criteria aligned with imbalance analysis needs\n",
    "   - Memory-efficient node structure for large datasets\n",
    "\n",
    "3. Phase 2 Readiness:\n",
    "   - Modular impurity calculations for weighted Gini modification\n",
    "   - Class label preservation for imbalance weighting\n",
    "   - Predict method optimized for probability-based metrics (ROC-AUC)\n",
    "\n",
    "Implementation Differences from Reference:\n",
    "- No sklearn dependencies\n",
    "- Removed print_tree visualization methods\n",
    "- Simplified split criteria to essential parameters\n",
    "- Vectorized impurity calculations for performance\n",
    "- Added sample counting for imbalance analysis\n",
    "\n",
    "Important Notes:\n",
    "- Designed for binary classification (handles multi-class through majority voting)\n",
    "- Requires preprocessed numerical features (compatible with utils/preprocess.py)\n",
    "- Class labels stored in self.classes for Phase 2 modifications\n",
    "\n",
    "Maintains Core CART Functionality:\n",
    "- Gini/Entropy split criteria\n",
    "- Depth-based stopping\n",
    "- Recursive tree construction\n",
    "- Majority class prediction\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there was so much data missing from the datasets, whether it was a row with many NaN (Not a Number) values or a column with the same issue, we thought the best way to solve that was to preprocess the datasets' data. So we came up with the following program, which reads the data first (in data/raw) and then processes them. Then, it inserts the processed data into the data/processed directory, where the trained and tested data are all separated in different files (X_train.csv, X_test.csv, y_train.csv, y_test.csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/processed/class_imbalance:\n",
      "Processing dataset_978_mfeat-factors.csv...\n",
      "Classes: ['N', 'P'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_947_arsenic-male-bladder.csv...\n",
      "Classes: ['N', 'P'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_1004_synthetic_control.csv...\n",
      "Classes: ['N', 'P'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_1056_mc1.csv...\n",
      "Classes: [np.False_, np.True_] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_940_water-treatment.csv...\n",
      "Classes: ['N', 'P'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_950_arsenic-female-lung.csv...\n",
      "Classes: ['N', 'P'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_1014_analcatdata_dmft.csv...\n",
      "Classes: ['N', 'P'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_1039_hiva_agnostic.csv...\n",
      "Classes: [np.int64(-1), np.int64(1)] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_1018_ipums_la_99-small.csv...\n",
      "Classes: ['N', 'P'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_1002_ipums_la_98-small.csv...\n",
      "Classes: ['N', 'P'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_765_analcatdata_apnea2.csv...\n",
      "Classes: ['N', 'P'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_1016_vowel.csv...\n",
      "Classes: ['N', 'P'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_1045_kc1-top5.csv...\n",
      "Classes: ['DEF', 'NODEF'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_1013_analcatdata_challenger.csv...\n",
      "Classes: [np.int64(0), np.int64(1)] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_450_analcatdata_lawsuit.csv...\n",
      "Classes: [np.int64(0), np.int64(1)] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_312_scene.csv...\n",
      "Classes: [np.int64(0), np.int64(1)] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_995_mfeat-zernike.csv...\n",
      "Classes: ['N', 'P'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_764_analcatdata_apnea3.csv...\n",
      "Classes: ['N', 'P'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_311_oil_spill.csv...\n",
      "Classes: [np.int64(-1), np.int64(1)] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_980_optdigits.csv...\n",
      "Classes: ['N', 'P'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_968_analcatdata_birthday.csv...\n",
      "Classes: ['N', 'P'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_987_collins.csv...\n",
      "Classes: ['N', 'P'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_767_analcatdata_apnea1.csv...\n",
      "Classes: ['N', 'P'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_875_analcatdata_chlamydia.csv...\n",
      "Classes: ['N', 'P'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_1061_ar4.csv...\n",
      "Classes: [np.False_, np.True_] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_962_mfeat-morphological.csv...\n",
      "Classes: ['N', 'P'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_757_meta.csv...\n",
      "Classes: ['N', 'P'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_951_arsenic-male-lung.csv...\n",
      "Classes: ['N', 'P'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_958_segment.csv...\n",
      "Classes: ['N', 'P'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_1064_ar6.csv...\n",
      "Classes: [np.False_, np.True_] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_1050_pc3.csv...\n",
      "Classes: [np.False_, np.True_] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_463_backache.csv...\n",
      "Classes: [np.int64(0), np.int64(1)] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_1000_hypothyroid.csv...\n",
      "Classes: ['N', 'P'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_1049_pc4.csv...\n",
      "Classes: [np.False_, np.True_] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_1023_soybean.csv...\n",
      "Classes: ['N', 'P'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_316_yeast_ml8.csv...\n",
      "Classes: [np.int64(0), np.int64(1)] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_949_arsenic-female-bladder.csv...\n",
      "Classes: ['N', 'P'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_1022_mfeat-pixel.csv...\n",
      "Classes: ['N', 'P'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_954_spectrometer.csv...\n",
      "Classes: ['N', 'P'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_966_analcatdata_halloffame.csv...\n",
      "Classes: ['N', 'P'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_971_mfeat-fourier.csv...\n",
      "Classes: ['N', 'P'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_1065_kc3.csv...\n",
      "Classes: [np.False_, np.True_] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_1021_page-blocks.csv...\n",
      "Classes: ['N', 'P'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_1020_mfeat-karhunen.csv...\n",
      "Classes: ['N', 'P'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_1059_ar1.csv...\n",
      "Classes: [np.False_, np.True_] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_867_visualizing_livestock.csv...\n",
      "Classes: ['N', 'P'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_38_sick.csv...\n",
      "Classes: ['negative', 'sick'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_984_analcatdata_draft.csv...\n",
      "Classes: ['N', 'P'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_865_analcatdata_neavote.csv...\n",
      "Classes: ['N', 'P'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_976_JapaneseVowels.csv...\n",
      "Classes: ['N', 'P'] → [np.int64(0), np.int64(1)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "\n",
    "\n",
    "def preprocess_datasets(\n",
    "    raw_dir=\"data/raw/class_imbalance\",\n",
    "    processed_dir=\"data/processed/class_imbalance\",\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "):\n",
    "    \"\"\"\n",
    "    Preprocess datasets with robust label encoding and validation\n",
    "    \"\"\"\n",
    "    os.makedirs(processed_dir, exist_ok=True)\n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    for filename in os.listdir(raw_dir):\n",
    "        if not filename.endswith(\".csv\"):\n",
    "            continue\n",
    "\n",
    "        print(f\"{processed_dir}:\")\n",
    "        print(f\"Processing {filename}...\")\n",
    "        file_path = os.path.join(raw_dir, filename)\n",
    "\n",
    "        try:\n",
    "            # Load and validate data\n",
    "            df = pd.read_csv(file_path)\n",
    "            if df.shape[1] < 2:\n",
    "                print(f\"Skipping {filename}: Insufficient columns\")\n",
    "                continue\n",
    "\n",
    "            # Separate features and target\n",
    "            X = df.iloc[:, :-1].copy()\n",
    "            y_raw = df.iloc[:, -1].copy()\n",
    "\n",
    "            # Clean and encode labels\n",
    "            valid_mask = y_raw.notna()\n",
    "            X, y_raw = X[valid_mask], y_raw[valid_mask]\n",
    "            y_raw_sorted = np.sort(y_raw)\n",
    "            if len(y_raw_sorted) == 0:\n",
    "                print(f\"Skipping {filename}: No valid targets\")\n",
    "                continue\n",
    "\n",
    "            # Convert labels to 0-indexed integers\n",
    "            y = pd.Series(label_encoder.fit_transform(y_raw_sorted), name=y_raw.name)\n",
    "            classes = label_encoder.classes_\n",
    "            if len(classes) < 2:\n",
    "                print(f\"Skipping {filename}: Only one class present\")\n",
    "                continue\n",
    "\n",
    "            # Numerical imputation\n",
    "            num_cols = X.select_dtypes(include=np.number).columns\n",
    "            if len(num_cols) > 0:\n",
    "                X[num_cols] = X[num_cols].fillna(X[num_cols].mean()).fillna(0)\n",
    "\n",
    "            # Categorical imputation\n",
    "            cat_cols = X.select_dtypes(exclude=np.number).columns\n",
    "            for col in cat_cols:\n",
    "                mode = X[col].mode()[0] if not X[col].mode().empty else \"missing\"\n",
    "                X[col] = X[col].fillna(mode)\n",
    "\n",
    "            # Convert categoricals to dummies\n",
    "            if len(cat_cols) > 0:\n",
    "                X = pd.get_dummies(X, columns=cat_cols, drop_first=False)\n",
    "\n",
    "            # Final validation\n",
    "            X = X.fillna(0).infer_objects()\n",
    "            assert not X.isna().any().any(), \"NaN values in features\"\n",
    "            assert X.shape[0] > 0, \"Empty dataset after preprocessing\"\n",
    "\n",
    "            # Normalize numericals\n",
    "            num_cols = X.select_dtypes(include=np.number).columns\n",
    "            if len(num_cols) > 0:\n",
    "                X[num_cols] = MinMaxScaler().fit_transform(X[num_cols])\n",
    "\n",
    "            # Stratified split\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y, test_size=test_size, stratify=y, random_state=random_state\n",
    "            )\n",
    "\n",
    "            # Save processed data\n",
    "            base_name = os.path.splitext(filename)[0]\n",
    "            output_dir = os.path.join(processed_dir, base_name)\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "            X_train.to_csv(os.path.join(output_dir, \"X_train.csv\"), index=False)\n",
    "            X_test.to_csv(os.path.join(output_dir, \"X_test.csv\"), index=False)\n",
    "            y_train.to_csv(os.path.join(output_dir, \"y_train.csv\"), index=False)\n",
    "            y_test.to_csv(os.path.join(output_dir, \"y_test.csv\"), index=False)\n",
    "\n",
    "            print(f\"Classes: {list(classes)} → {list(y.unique())}\\n\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed processing {filename}: {str(e)}\\n\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    preprocess_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike the code that inspired our work (zziz/cart), our CART version has more than one class. It has two: one for the tree node (TreeNode) and the other for CART itself (DecisionTree)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class TreeNode:\n",
    "    \"\"\"Node structure for decision tree\"\"\"\n",
    "\n",
    "    def __init__(self, feature=None, threshold=None, left=None, right=None, value=None):\n",
    "        self.feature = feature  # Feature index for splitting\n",
    "        self.threshold = threshold  # Threshold value for split\n",
    "        self.left = left  # Left subtree\n",
    "        self.right = right  # Right subtree\n",
    "        self.value = value  # Class label for leaf nodes\n",
    "        self.samples = 0  # Number of samples in node\n",
    "        self.depth = 0  # Depth in tree structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    \"\"\"CART classifier with Gini/Entropy criteria for handling class imbalance analysis\"\"\"\n",
    "\n",
    "    def __init__(self, max_depth=None, min_samples_split=2, criterion=\"gini\"):\n",
    "        self.max_depth = max_depth  # Maximum tree depth\n",
    "        self.min_samples_split = min_samples_split  # Minimum samples to split\n",
    "        self.criterion = criterion.lower()  # Impurity measure (gini/entropy)\n",
    "        self.root = None  # Root node of decision tree\n",
    "        self.classes = None  # Store class labels\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Build decision tree from training data.\"\"\"\n",
    "        y = self._convert_labels(y)\n",
    "        self.classes = np.unique(y)\n",
    "        self.root = self._grow_tree(X, y, depth=0)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict class labels for input samples\"\"\"\n",
    "        return np.array([self._traverse(x, self.root) for x in X])\n",
    "\n",
    "    def _convert_labels(self, y):\n",
    "        \"\"\"Convert labels to np.int64. If conversion fails, map categorical labels to numbers.\"\"\"\n",
    "        try:\n",
    "            return y.astype(np.int64)\n",
    "        except ValueError:\n",
    "            uniques = np.unique(y)\n",
    "            mapping = {label: idx for idx, label in enumerate(uniques)}\n",
    "            return np.array([mapping[val] for val in y], dtype=np.int64)\n",
    "\n",
    "    def _grow_tree(self, X, y, depth):\n",
    "        \"\"\"Recursively build decision tree\"\"\"\n",
    "        node = TreeNode()\n",
    "        node.samples = X.shape[0]\n",
    "        node.depth = depth\n",
    "\n",
    "        # Stopping conditions\n",
    "        if (\n",
    "            (self.max_depth and depth >= self.max_depth)\n",
    "            or (node.samples < self.min_samples_split)\n",
    "            or (len(np.unique(y)) == 1)\n",
    "        ):\n",
    "            node.value = self._most_common(y)\n",
    "            return node\n",
    "\n",
    "        # Find optimal split\n",
    "        feature, threshold = self._best_split(X, y)\n",
    "        if feature is None:\n",
    "            node.value = self._most_common(y)\n",
    "            return node\n",
    "\n",
    "        # Split dataset\n",
    "        left_idx = X[:, feature] <= threshold\n",
    "        right_idx = ~left_idx\n",
    "\n",
    "        # Grow child nodes\n",
    "        node.feature = feature\n",
    "        node.threshold = threshold\n",
    "        node.left = self._grow_tree(X[left_idx], y[left_idx], depth + 1)\n",
    "        node.right = self._grow_tree(X[right_idx], y[right_idx], depth + 1)\n",
    "\n",
    "        return node\n",
    "\n",
    "    def _best_split(self, X, y):\n",
    "        \"\"\"Find optimal feature and threshold for splitting\"\"\"\n",
    "        best_gain = -1\n",
    "        best_feature, best_threshold = None, None\n",
    "        current_impurity = self._calculate_impurity(y)\n",
    "\n",
    "        for feature in range(X.shape[1]):\n",
    "            thresholds = np.unique(X[:, feature])\n",
    "            for threshold in thresholds:\n",
    "                left_y = y[X[:, feature] <= threshold]\n",
    "                right_y = y[X[:, feature] > threshold]\n",
    "\n",
    "                if len(left_y) == 0 or len(right_y) == 0:\n",
    "                    continue\n",
    "\n",
    "                gain = current_impurity - self._weighted_impurity(left_y, right_y)\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    best_feature = feature\n",
    "                    best_threshold = threshold\n",
    "\n",
    "        return best_feature, best_threshold\n",
    "\n",
    "    def _calculate_impurity(self, y):\n",
    "        \"\"\"Calculate impurity of target values\"\"\"\n",
    "        proportions = np.bincount(y) / len(y)\n",
    "\n",
    "        if self.criterion == \"gini\":\n",
    "            return 1 - np.sum(proportions**2)\n",
    "        elif self.criterion == \"entropy\":\n",
    "            return -np.sum(proportions * np.log2(proportions))\n",
    "        else:\n",
    "            raise ValueError(\"Invalid criterion. Use 'gini' or 'entropy'\")\n",
    "\n",
    "    def _weighted_impurity(self, left_y, right_y):\n",
    "        \"\"\"Calculate weighted impurity for child nodes\"\"\"\n",
    "        n_left, n_right = len(left_y), len(right_y)\n",
    "        n_total = n_left + n_right\n",
    "\n",
    "        return (n_left / n_total) * self._calculate_impurity(left_y) + (\n",
    "            n_right / n_total\n",
    "        ) * self._calculate_impurity(right_y)\n",
    "\n",
    "    def _most_common(self, y):\n",
    "        \"\"\"Find majority class label\"\"\"\n",
    "        return np.bincount(y).argmax()\n",
    "\n",
    "    def _traverse(self, x, node):\n",
    "        \"\"\"Traverse tree to make prediction\"\"\"\n",
    "        if node.value is not None:\n",
    "            return node.value\n",
    "        if x[node.feature] <= node.threshold:\n",
    "            return self._traverse(x, node.left)\n",
    "        return self._traverse(x, node.right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File evaluation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"data/processed/class_imbalance\"\n",
    "results = {}\n",
    "for dataset in os.listdir(base_dir):\n",
    "    results[dataset] = []\n",
    "    dataset_path = os.path.join(base_dir, dataset)\n",
    "    # Load preprocessed data\n",
    "    X_train = pd.read_csv(os.path.join(dataset_path, \"X_train.csv\")).values\n",
    "    y_train = pd.read_csv(os.path.join(dataset_path, \"y_train.csv\")).values.flatten()\n",
    "\n",
    "    # Initialize and train model\n",
    "    tree = DecisionTree(max_depth=5, criterion=\"gini\")\n",
    "    tree.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    X_test = pd.read_csv(os.path.join(dataset_path, \"X_test.csv\")).values\n",
    "    predictions = tree.predict(X_test)\n",
    "\n",
    "    y_test = pd.read_csv(os.path.join(dataset_path, \"y_test.csv\")).values.flatten()\n",
    "    accuracy = np.mean(predictions == y_test)\n",
    "    results[dataset].append(accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Empricial evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dataset_995_mfeat-zernike</th>\n",
       "      <td>0.873333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_875_analcatdata_chlamydia</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_1061_ar4</th>\n",
       "      <td>0.696970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_1020_mfeat-karhunen</th>\n",
       "      <td>0.943333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_966_analcatdata_halloffame</th>\n",
       "      <td>0.900498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_765_analcatdata_apnea2</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_1065_kc3</th>\n",
       "      <td>0.869565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_984_analcatdata_draft</th>\n",
       "      <td>0.990909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_968_analcatdata_birthday</th>\n",
       "      <td>0.981818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_1021_page-blocks</th>\n",
       "      <td>0.899513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_450_analcatdata_lawsuit</th>\n",
       "      <td>0.975000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_1016_vowel</th>\n",
       "      <td>0.986532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_1049_pc4</th>\n",
       "      <td>0.872146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_867_visualizing_livestock</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_1022_mfeat-pixel</th>\n",
       "      <td>0.936667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_767_analcatdata_apnea1</th>\n",
       "      <td>0.993007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_1045_kc1-top5</th>\n",
       "      <td>0.954545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_316_yeast_ml8</th>\n",
       "      <td>0.980716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_949_arsenic-female-bladder</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_950_arsenic-female-lung</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_951_arsenic-male-lung</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_865_analcatdata_neavote</th>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_1004_synthetic_control</th>\n",
       "      <td>0.938889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_978_mfeat-factors</th>\n",
       "      <td>0.975000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_1000_hypothyroid</th>\n",
       "      <td>0.914311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_1064_ar6</th>\n",
       "      <td>0.741935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_1059_ar1</th>\n",
       "      <td>0.783784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_312_scene</th>\n",
       "      <td>0.813278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_987_collins</th>\n",
       "      <td>0.993333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_1013_analcatdata_challenger</th>\n",
       "      <td>0.976190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_954_spectrometer</th>\n",
       "      <td>0.987500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_962_mfeat-morphological</th>\n",
       "      <td>0.898333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_1039_hiva_agnostic</th>\n",
       "      <td>0.959811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_980_optdigits</th>\n",
       "      <td>0.897390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_1050_pc3</th>\n",
       "      <td>0.884861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_940_water-treatment</th>\n",
       "      <td>0.880503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_971_mfeat-fourier</th>\n",
       "      <td>0.906667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_958_segment</th>\n",
       "      <td>0.836941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_1014_analcatdata_dmft</th>\n",
       "      <td>0.804167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_38_sick</th>\n",
       "      <td>0.938163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_311_oil_spill</th>\n",
       "      <td>0.996454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_1002_ipums_la_98-small</th>\n",
       "      <td>0.893143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_757_meta</th>\n",
       "      <td>0.987421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_463_backache</th>\n",
       "      <td>0.796296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_976_JapaneseVowels</th>\n",
       "      <td>0.865172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_1023_soybean</th>\n",
       "      <td>0.902439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_764_analcatdata_apnea3</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_1056_mc1</th>\n",
       "      <td>0.990493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_947_arsenic-male-bladder</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_1018_ipums_la_99-small</th>\n",
       "      <td>0.932178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Accuracy\n",
       "dataset_995_mfeat-zernike            0.873333\n",
       "dataset_875_analcatdata_chlamydia    1.000000\n",
       "dataset_1061_ar4                     0.696970\n",
       "dataset_1020_mfeat-karhunen          0.943333\n",
       "dataset_966_analcatdata_halloffame   0.900498\n",
       "dataset_765_analcatdata_apnea2       1.000000\n",
       "dataset_1065_kc3                     0.869565\n",
       "dataset_984_analcatdata_draft        0.990909\n",
       "dataset_968_analcatdata_birthday     0.981818\n",
       "dataset_1021_page-blocks             0.899513\n",
       "dataset_450_analcatdata_lawsuit      0.975000\n",
       "dataset_1016_vowel                   0.986532\n",
       "dataset_1049_pc4                     0.872146\n",
       "dataset_867_visualizing_livestock    1.000000\n",
       "dataset_1022_mfeat-pixel             0.936667\n",
       "dataset_767_analcatdata_apnea1       0.993007\n",
       "dataset_1045_kc1-top5                0.954545\n",
       "dataset_316_yeast_ml8                0.980716\n",
       "dataset_949_arsenic-female-bladder   1.000000\n",
       "dataset_950_arsenic-female-lung      1.000000\n",
       "dataset_951_arsenic-male-lung        1.000000\n",
       "dataset_865_analcatdata_neavote      0.933333\n",
       "dataset_1004_synthetic_control       0.938889\n",
       "dataset_978_mfeat-factors            0.975000\n",
       "dataset_1000_hypothyroid             0.914311\n",
       "dataset_1064_ar6                     0.741935\n",
       "dataset_1059_ar1                     0.783784\n",
       "dataset_312_scene                    0.813278\n",
       "dataset_987_collins                  0.993333\n",
       "dataset_1013_analcatdata_challenger  0.976190\n",
       "dataset_954_spectrometer             0.987500\n",
       "dataset_962_mfeat-morphological      0.898333\n",
       "dataset_1039_hiva_agnostic           0.959811\n",
       "dataset_980_optdigits                0.897390\n",
       "dataset_1050_pc3                     0.884861\n",
       "dataset_940_water-treatment          0.880503\n",
       "dataset_971_mfeat-fourier            0.906667\n",
       "dataset_958_segment                  0.836941\n",
       "dataset_1014_analcatdata_dmft        0.804167\n",
       "dataset_38_sick                      0.938163\n",
       "dataset_311_oil_spill                0.996454\n",
       "dataset_1002_ipums_la_98-small       0.893143\n",
       "dataset_757_meta                     0.987421\n",
       "dataset_463_backache                 0.796296\n",
       "dataset_976_JapaneseVowels           0.865172\n",
       "dataset_1023_soybean                 0.902439\n",
       "dataset_764_analcatdata_apnea3       1.000000\n",
       "dataset_1056_mc1                     0.990493\n",
       "dataset_947_arsenic-male-bladder     1.000000\n",
       "dataset_1018_ipums_la_99-small       0.932178"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame.from_dict(results, orient='index', columns=['Accuracy'])\n",
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
