{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCART Implementation for Class Imbalance Study\\n\\nOriginal Reference Implementation:\\n- Adapted from zziz/cart (https://github.com/zziz/cart)\\n- Clean-room implementation without direct code copying\\n\\nKey Modifications from Reference:\\n1. Architecture Simplification:\\n   - Removed regression functionality to focus purely on classification\\n   - Unified tree structure with dedicated TreeNode class\\n   - Simplified API (removed pruning parameters, consolidated initialization)\\n\\n2. Project-Specific Optimizations:\\n   - Direct compatibility with preprocessed numpy arrays (from data/processed/)\\n   - Binary classification focus with class label tracking\\n   - Early stopping criteria aligned with imbalance analysis needs\\n   - Memory-efficient node structure for large datasets\\n\\n3. Phase 2 Readiness:\\n   - Modular impurity calculations for weighted Gini modification\\n   - Class label preservation for imbalance weighting\\n   - Predict method optimized for probability-based metrics (ROC-AUC)\\n\\nImplementation Differences from Reference:\\n- No sklearn dependencies\\n- Removed print_tree visualization methods\\n- Simplified split criteria to essential parameters\\n- Vectorized impurity calculations for performance\\n- Added sample counting for imbalance analysis\\n\\nImportant Notes:\\n- Designed for binary classification (handles multi-class through majority voting)\\n- Requires preprocessed numerical features (compatible with utils/preprocess.py)\\n- Class labels stored in self.classes for Phase 2 modifications\\n\\nMaintains Core CART Functionality:\\n- Gini/Entropy split criteria\\n- Depth-based stopping\\n- Recursive tree construction\\n- Majority class prediction\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "CART Implementation for Class Imbalance Study\n",
    "\n",
    "Original Reference Implementation:\n",
    "- Adapted from zziz/cart (https://github.com/zziz/cart)\n",
    "- Clean-room implementation without direct code copying\n",
    "\n",
    "Key Modifications from Reference:\n",
    "1. Architecture Simplification:\n",
    "   - Removed regression functionality to focus purely on classification\n",
    "   - Unified tree structure with dedicated TreeNode class\n",
    "   - Simplified API (removed pruning parameters, consolidated initialization)\n",
    "\n",
    "2. Project-Specific Optimizations:\n",
    "   - Direct compatibility with preprocessed numpy arrays (from data/processed/)\n",
    "   - Binary classification focus with class label tracking\n",
    "   - Early stopping criteria aligned with imbalance analysis needs\n",
    "   - Memory-efficient node structure for large datasets\n",
    "\n",
    "3. Phase 2 Readiness:\n",
    "   - Modular impurity calculations for weighted Gini modification\n",
    "   - Class label preservation for imbalance weighting\n",
    "   - Predict method optimized for probability-based metrics (ROC-AUC)\n",
    "\n",
    "Implementation Differences from Reference:\n",
    "- No sklearn dependencies\n",
    "- Removed print_tree visualization methods\n",
    "- Simplified split criteria to essential parameters\n",
    "- Vectorized impurity calculations for performance\n",
    "- Added sample counting for imbalance analysis\n",
    "\n",
    "Important Notes:\n",
    "- Designed for binary classification (handles multi-class through majority voting)\n",
    "- Requires preprocessed numerical features (compatible with utils/preprocess.py)\n",
    "- Class labels stored in self.classes for Phase 2 modifications\n",
    "\n",
    "Maintains Core CART Functionality:\n",
    "- Gini/Entropy split criteria\n",
    "- Depth-based stopping\n",
    "- Recursive tree construction\n",
    "- Majority class prediction\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "root = os.getcwd()  # current working directory should be the project root\n",
    "src_path = os.path.join(root, \"src\")\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there was so much data missing from the datasets, whether it was a row with many NaN (Not a Number) values or a column with the same issue, we thought the best way to solve that was to preprocess the datasets' data. So we came up with the following program, which reads the data first (in data/raw) and then processes them. Then, it inserts the processed data into the data/processed directory, where the trained and tested data are all separated in different files (X_train.csv, X_test.csv, y_train.csv, y_test.csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/processed/class_imbalance:\n",
      "Processing dataset_1000_hypothyroid.csv...\n",
      "Classes: ['N', 'P'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_1002_ipums_la_98-small.csv...\n",
      "Classes: ['N', 'P'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_1004_synthetic_control.csv...\n",
      "Classes: ['N', 'P'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_1013_analcatdata_challenger.csv...\n",
      "Classes: [np.int64(0), np.int64(1)] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_1014_analcatdata_dmft.csv...\n",
      "Classes: ['N', 'P'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_1016_vowel.csv...\n",
      "Classes: ['N', 'P'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_1018_ipums_la_99-small.csv...\n",
      "Classes: ['N', 'P'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_1020_mfeat-karhunen.csv...\n",
      "Classes: ['N', 'P'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_1021_page-blocks.csv...\n",
      "Classes: ['N', 'P'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_1022_mfeat-pixel.csv...\n",
      "Classes: ['N', 'P'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_1023_soybean.csv...\n",
      "Classes: ['N', 'P'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_1039_hiva_agnostic.csv...\n",
      "Classes: [np.int64(-1), np.int64(1)] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_1045_kc1-top5.csv...\n",
      "Classes: ['DEF', 'NODEF'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_1049_pc4.csv...\n",
      "Classes: [np.False_, np.True_] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_1050_pc3.csv...\n",
      "Classes: [np.False_, np.True_] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_1056_mc1.csv...\n",
      "Classes: [np.False_, np.True_] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_1059_ar1.csv...\n",
      "Classes: [np.False_, np.True_] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_1061_ar4.csv...\n",
      "Classes: [np.False_, np.True_] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_1064_ar6.csv...\n",
      "Classes: [np.False_, np.True_] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_1065_kc3.csv...\n",
      "Classes: [np.False_, np.True_] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_311_oil_spill.csv...\n",
      "Classes: [np.int64(-1), np.int64(1)] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_312_scene.csv...\n",
      "Classes: [np.int64(0), np.int64(1)] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_316_yeast_ml8.csv...\n",
      "Classes: [np.int64(0), np.int64(1)] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_38_sick.csv...\n",
      "Classes: ['negative', 'sick'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_450_analcatdata_lawsuit.csv...\n",
      "Classes: [np.int64(0), np.int64(1)] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_463_backache.csv...\n",
      "Classes: [np.int64(0), np.int64(1)] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_757_meta.csv...\n",
      "Classes: ['N', 'P'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_764_analcatdata_apnea3.csv...\n",
      "Classes: ['N', 'P'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_765_analcatdata_apnea2.csv...\n",
      "Classes: ['N', 'P'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_767_analcatdata_apnea1.csv...\n",
      "Classes: ['N', 'P'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_865_analcatdata_neavote.csv...\n",
      "Classes: ['N', 'P'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_867_visualizing_livestock.csv...\n",
      "Classes: ['N', 'P'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_875_analcatdata_chlamydia.csv...\n",
      "Classes: ['N', 'P'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_940_water-treatment.csv...\n",
      "Classes: ['N', 'P'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_947_arsenic-male-bladder.csv...\n",
      "Classes: ['N', 'P'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_949_arsenic-female-bladder.csv...\n",
      "Classes: ['N', 'P'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_950_arsenic-female-lung.csv...\n",
      "Classes: ['N', 'P'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_951_arsenic-male-lung.csv...\n",
      "Classes: ['N', 'P'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_954_spectrometer.csv...\n",
      "Classes: ['N', 'P'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_958_segment.csv...\n",
      "Classes: ['N', 'P'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_962_mfeat-morphological.csv...\n",
      "Classes: ['N', 'P'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_966_analcatdata_halloffame.csv...\n",
      "Classes: ['N', 'P'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_968_analcatdata_birthday.csv...\n",
      "Classes: ['N', 'P'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_971_mfeat-fourier.csv...\n",
      "Classes: ['N', 'P'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_976_JapaneseVowels.csv...\n",
      "Classes: ['N', 'P'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_978_mfeat-factors.csv...\n",
      "Classes: ['N', 'P'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_980_optdigits.csv...\n",
      "Classes: ['N', 'P'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_984_analcatdata_draft.csv...\n",
      "Classes: ['N', 'P'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_987_collins.csv...\n",
      "Classes: ['N', 'P'] → [np.int64(0), np.int64(1)]\n",
      "\n",
      "data/processed/class_imbalance:\n",
      "Processing dataset_995_mfeat-zernike.csv...\n",
      "Classes: ['N', 'P'] → [np.int64(0), np.int64(1)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from utils.preprocess import preprocess_datasets\n",
    "\n",
    "preprocess_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike the code that inspired our work (zziz/cart), our CART version has more than one class. It has two: one for the tree node (TreeNode) and the other for CART itself (DecisionTree)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File evaluation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'evaluate' from 'utils.evaluation' (c:\\Users\\LENOVO\\Desktop\\fcup\\aprendizagem-computacional-1\\project\\src\\utils\\evaluation.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m evaluate\n\u001b[0;32m      3\u001b[0m results \u001b[38;5;241m=\u001b[39m evaluate(data_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/processed/class_imbalance/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'evaluate' from 'utils.evaluation' (c:\\Users\\LENOVO\\Desktop\\fcup\\aprendizagem-computacional-1\\project\\src\\utils\\evaluation.py)"
     ]
    }
   ],
   "source": [
    "from utils.evaluation import evaluate\n",
    "\n",
    "results = evaluate(data_dir=\"data/processed/class_imbalance/\")\n",
    "results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
